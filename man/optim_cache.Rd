% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim_cache.R
\name{optim_cache}
\alias{optim_cache}
\title{Run the \code{optim} Optimization Function with a Cached
    Gradient}
\usage{
optim_cache(
  par,
  fn,
  gr = NULL,
  ...,
  method = c("BFGS", "CG", "L-BFGS-B"),
  lower = -Inf,
  upper = Inf,
  control = list(),
  hessian = FALSE
)
}
\arguments{
\item{par}{The initial values for the parameters to be optimized
over as in \code{\link[stats]{optim}}.}

\item{fn}{The function to be minimized. As a major difference with
\code{optim}, this function must return a list with \emph{two
elements} \code{objective} and \code{gradient} (vector).}

\item{gr}{Can not be used. This argument is for compatibility with
\code{\link[stats]{optim}}. It can be removed in future
versions.}

\item{...}{Further arguments to be passed to
\code{\link[stats]{optim}}.}

\item{method}{As in \code{\link[stats]{optim}}. Since we are
always using the gradient in this function, only the methods
\code{"BFGS"}, \code{"CG"} \code{"L-BFGS-B"} can be used here.}

\item{lower, upper, hessian, control}{See \code{\link[stats]{optim}}.}
}
\value{
A list with the same structure as that returned by
    \code{\link[stats]{optim}}. It contains \code{par} and
    \code{value} giving the best set of parameters found and to
    the value of \code{fn} corresponding to \code{par}.
}
\description{
Run the \code{\link[stats]{optim}} function from
    the \pkg{stats} package with the objective and the gradient
    defined in \emph{one} function. The result is global
    minimization of a real-valued function of a numeric vector
    with length \eqn{d} to be provided by \code{fn}. The R
    function \code{fn} must provide the values of the objective
    and its gradient.

    The formal arguments of this function and their default values
    are those of the \code{\link[stats]{optim}} function at the
    time when this function is written, based on version
    \code{4.1.2} of \pkg{R}. The \code{optim} function is unlikely
    to be changed in the future.
}
\examples{
## Note that in this example, gradient caching would not be worth it.

## emulate a costly-to-evaluate-alone gradient
## ===========================================
braninDer <- function(x) {
   Sys.sleep(0.01)
   branin_with_grad(x)$gradient
}

## separate objective and gradient functions
## =========================================
te <-
    system.time(res <- optim(par = c(0.5, 0.5), fn = branin, gr = braninDer))

## gradient "cached"
## ================
teCache <-
    system.time(resCache <- optim_cache(par = c(0.5, 0.5), fn = branin_with_grad))
rbind("optim" = te, "optim_cache" = teCache)
c("optim" = res$value, "optim_cache" = resCache$value)

## Check the use of ...
## ====================
braninShift <- function(x, shift = 0) {
    res <- branin_with_grad(x)
    res$objective <- res$objective + shift
    res
}
resShifted <- optim_cache(par = c(0.5, 0.5), fn = braninShift, shift = 100)
c("optim_cache" = resCache$value, "optimShifted" = resShifted$value - 100)

}
