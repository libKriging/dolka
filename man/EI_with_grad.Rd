% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EI_with_grad.R
\name{EI_with_grad}
\alias{EI_with_grad}
\title{Expected Improvement Criterion With Gradient}
\usage{
EI_with_grad(
  x,
  model,
  plugin = NULL,
  type = c("UK", "SK"),
  minimization = TRUE,
  proxy = FALSE,
  deriv = TRUE,
  out_list = deriv
)
}
\arguments{
\item{x}{A numeric vector representing the input for which one
wishes to calculate EI. The length \eqn{d} of this vector must
be equal to \eqn{d}, the dimension of the input space used for
the kriging results in \code{model}.}

\item{model}{An object of class \code{\link[DiceKriging]{km}}.}

\item{plugin}{Optional scalar: if provided, it replaces the
minimum of the current observations.}

\item{type}{\code{"UK"} (default) or \code{"SK"}, depending
whether uncertainty related to trend estimation has to be
taken into account.}

\item{minimization}{Logical specifying if EI is used in
minimization or in maximization.}

\item{proxy}{Optional logical. If \code{TRUE}, EI is replaced by
the kriging mean, to be \emph{minimized}.}

\item{deriv}{Logical. If \code{TRUE} the result is a list with the
two elements \code{objective} and \code{gradient}. Else
the result is the value of the objective.}

\item{out_list}{Logical When \code{out_list} is \code{TRUE} the
result is a \emph{list} with one element \code{objective}. If
\code{deriv} is \code{TRUE} the list has a second element
\code{gradient}. When \code{out_list} is \code{FALSE} the
result is the numerical value of the objective, possibly
having an attribute named \code{"gradient"}.}
}
\value{
The expected improvement as defined in \bold{Details}
    (for \code{EI}) or its gradient (for \code{EI.grad}).  If
    \code{plugin} is specified, its provided value will replace
    \eqn{\min Y(X)}{min Y(X)} in the formula. The EI and its
    gradient are numeric vectors with length \eqn{1} and \eqn{d}.
}
\description{
The function \code{EI_with_grad} computes the
    Expected Improvement at current location \code{x} and its
    gradient if wanted. The current minimum of the observations in
    \code{model} can be replaced by an arbitrary value (plugin),
    which is useful in particular in noisy frameworks.
}
\details{
The Expected Improvement (EI) is defined as \deqn{EI(x)
    := E\left[\{\min Y(X) - Y(x)\}_+ | Y(X) = y(X) \right],}{ E[{
    min Y(X) - Y(x) }_+ | Y(X) = y(X)]} where \eqn{X} is the
    current design of experiments and \eqn{Y} is the random
    process assumed to have generated the objective function
    \eqn{y} and \eqn{z_{+} := \max\{z, \, 0)}{z_+ = max(z, 0)}
    denotes the positive part of a real number \eqn{z}. The value
    of EI is non-negative but can be numerically zero close to the
    inputs used in \code{model}. The EI and its gradient are
    computed using their closed forms.
}
\references{
D. Ginsbourger (2009), \emph{Multiples métamodèles pour
l'approximation et l'optimisation de fonctions numériques
multivariables}, Ph.D. thesis, Ècole Nationale Supérieure des
Mines de Saint-Ètienne.

D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, \emph{Journal of Global
Optimization}, 13, 455-492.

J. Mockus (1988), \emph{Bayesian Approach to Global
Optimization}. Kluwer academic publishers.

T.J. Santner, B.J. Williams, and W.J. Notz (2003), \emph{The
design and analysis of computer experiments}, Springer.

M. Schonlau (1997), \emph{Computer experiments and global
optimization}, Ph.D. thesis, University of Waterloo.
}
\seealso{
\code{\link{max_EI}}, \code{\link{EGO.nsteps}},
    \code{\link{qEI}}, \code{\link{EI}} and \code{\link{EI.grad}}.
}
\author{
David Ginsbourger, Olivier Roustant and Victor Picheny.
}
\keyword{models}
